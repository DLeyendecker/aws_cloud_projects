# Repositório de Big Data com AWS EMR e Python

Neste repositório, compartilho um projeto de Big Data que utiliza AWS Elastic MapReduce (EMR) e Python. O objetivo é mostrar como configurar e executar jobs para processamento distribuído de grandes volumes de dados na nuvem.

## Tecnologias Utilizadas

- **AWS EMR:** Serviço para processamento de dados em larga escala.
- **MrJob:** Biblioteca Python para definir e executar jobs MapReduce no EMR.
- **AWS S3:** Armazenamento de dados para entrada e saída dos jobs.

## Desafios Enfrentados

- **Configuração de Ambiente:** Configurar corretamente as credenciais e recursos do EMR.
- **Gerenciamento de Recursos:** Garantir eficiência na criação e gestão de clusters EMR.
- **Execução de Jobs Distribuídos:** Dividir e processar dados de maneira eficaz.
- **Armazenamento de Dados:** Configurar corretamente os diretórios no S3.
- **Monitoramento:** Acompanhar e diagnosticar problemas na execução dos jobs.

Este projeto demonstra a integração dessas tecnologias para o processamento eficiente de dados em larga escala.
